{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Yiran Xu\n",
    "\n",
    "Student Netid: yx1350\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Case study\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer for Part 1\n",
    "Business Goal: Identify women that are pregnant before the release of public birth records.\n",
    "Motivation: \n",
    "Not only pregnant women will buy a lot of new things, they are also expected to change their shopping patterns around the birth of a child.  There are chances that they will start buying everything in one store instead of buying different things at different store. Thus, if Target can send specialized ads to those pregnant women, those women might end up buying everything in Target and being a loyal customer for years. \n",
    "\n",
    "However, since birth records are usually public, it is crucial for Target to identify pregnant women before the release of public birth records. Otherwise, pregnant women will get so many advertising flyers that the one from Target could be easily ignored. \n",
    "\n",
    "Data Prediction Proposal:\n",
    "This is a supervised classification problem. \n",
    "Data Prediction goal: predict whether an individual is pregnant or not. \n",
    "The target variable is pregnant or not. If the value of the target variable is yes, we know this woman is pregnant. If the value is no, we know this woman is not pregnant.\n",
    "The potential features could be age, educational level, employed or unemployed, married or not, recent shopping records, whether there is a change in grocery shopping pattern, purchase of pregnancy-related nutrition supplements, how many kids one has currently, the age of the last born kids, estimated salary, what websites one recently visits frequently, the type of accounts one follows on social media, the google search records.\n",
    "\n",
    "Model selection:\n",
    "We can use classification tree to predict target value and its probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell on EC2 (see original directions) and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10341\r\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "!cat advertising_events.csv | wc -l \n",
    " #answer is 10341 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     732\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d \",\" -f 1 advertising_events.csv | sort| uniq|wc -l\n",
    "#answer is 732"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google.com\r\n",
      "facebook.com\r\n",
      "youtube.com\r\n",
      "yahoo.com\r\n",
      "baidu.com\r\n",
      "wikipedia.org\r\n",
      "amazon.com\r\n",
      "qq.com\r\n",
      "twitter.com\r\n",
      "taobao.com\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d \",\" -f 3 advertising_events.csv | sort|uniq -c |sort -n -r|awk '{print $2}' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "!grep -w \"37\" advertising_events.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"data/ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbuyer</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>visit_freq</th>\n",
       "      <th>buy_interval</th>\n",
       "      <th>sv_interval</th>\n",
       "      <th>expected_time_buy</th>\n",
       "      <th>expected_time_visit</th>\n",
       "      <th>last_buy</th>\n",
       "      <th>last_visit</th>\n",
       "      <th>multiple_buy</th>\n",
       "      <th>multiple_visit</th>\n",
       "      <th>uniq_urls</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>y_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>2130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-101.14930</td>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.79167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-106.18830</td>\n",
       "      <td>121</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.47917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.14473</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaT</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     isbuyer  buy_freq  visit_freq  buy_interval  sv_interval  \\\n",
       "NaT        0       NaN           1           0.0      0.00000   \n",
       "NaT        0       NaN           1           0.0      0.00000   \n",
       "NaT        0       NaN           1           0.0      0.00000   \n",
       "NaT        0       NaN           1           0.0      0.00000   \n",
       "NaT        0       NaN           2           0.0      0.50000   \n",
       "NaT        0       NaN           1           0.0      0.00000   \n",
       "NaT        0       NaN           1           0.0      0.00000   \n",
       "NaT        0       NaN           2           0.0     29.79167   \n",
       "NaT        0       NaN           3           0.0     45.47917   \n",
       "NaT        0       NaN           1           0.0      0.00000   \n",
       "\n",
       "     expected_time_buy  expected_time_visit  last_buy  last_visit  \\\n",
       "NaT                0.0              0.00000       106         106   \n",
       "NaT                0.0              0.00000        72          72   \n",
       "NaT                0.0              0.00000         5           5   \n",
       "NaT                0.0              0.00000         6           6   \n",
       "NaT                0.0           -101.14930       101         101   \n",
       "NaT                0.0              0.00000        42          42   \n",
       "NaT                0.0              0.00000        42          42   \n",
       "NaT                0.0           -106.18830       121         121   \n",
       "NaT                0.0            -34.14473        64          64   \n",
       "NaT                0.0              0.00000        13          13   \n",
       "\n",
       "     multiple_buy  multiple_visit  uniq_urls  num_checkins  y_buy  \n",
       "NaT             0               0        169          2130      0  \n",
       "NaT             0               0        154          1100      0  \n",
       "NaT             0               0          4            12      0  \n",
       "NaT             0               0        150           539      0  \n",
       "NaT             0               1        103           362      0  \n",
       "NaT             0               0         17            35      0  \n",
       "NaT             0               0         42           110      0  \n",
       "NaT             0               1        101           401      0  \n",
       "NaT             0               1        100           298      0  \n",
       "NaT             0               0         53           247      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "#adsTsv = pd.read_csv('/Users/yiranxu/Documents/NYUstudyMaterial/Fall2016/DSGA1001/HW/ads_dataset.tsv')\n",
    "#â€œ../file.csv\"\n",
    "adsTsv = pd.read_csv('ads_dataset.tsv')\n",
    "from pandas import DataFrame\n",
    "#convert tsv file to csv file to take advantage of built-in functions\n",
    "#ads = DataFrame.from_csv(\"/Users/yiranxu/Documents/NYUstudyMaterial/Fall2016/DSGA1001/HW/ads_dataset.tsv\", sep=\"\\t\")\n",
    "ads = DataFrame.from_csv(\"ads_dataset.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    # Place your code here\n",
    "    summary=input_data.describe().transpose() #get a dataframe summary statistics(there is no number_nan,nunber_distinct columns)\n",
    "    number_nan = pd.Series(input_data.isnull().sum(), name = 'number_nan') #count the number of missing not-a-number values and convert it to series\n",
    "    summary.insert(0, 'number_nan', number_nan) #insert the above series into summary dataframe as the first column \n",
    "    #notice describe() has already excluded NaN values\n",
    "    #use Series.value_counts to ignore missing, NA, and Null values:\n",
    "    number_distinct=input_data.apply(lambda x: len(x.value_counts())) #get number of distinct values a variable can take on for each variable\n",
    "    summary.insert(1, 'number_distinct', number_distinct) #insert into summary dataframe as the second column \n",
    "    return  summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranxu/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 89.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "%timeit getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###### Answer: \n",
    "buy_freq contains missing NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiranxu/anaconda/lib/python3.5/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>52257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>1.651549</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>84.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>0</td>\n",
       "      <td>5112</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>5.686388</td>\n",
       "      <td>17.623555</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>184.91670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>0</td>\n",
       "      <td>13351</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>-9.669298</td>\n",
       "      <td>31.239030</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.40192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>188.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.255602</td>\n",
       "      <td>0.436203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>86.656180</td>\n",
       "      <td>61.996711</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>206.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>0</td>\n",
       "      <td>4570</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>721.848518</td>\n",
       "      <td>1284.504018</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>37091.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     number_nan  number_distinct    count        mean  \\\n",
       "isbuyer                       0                1  52257.0    0.000000   \n",
       "buy_freq                  52257                0      0.0         NaN   \n",
       "visit_freq                    0               48  52257.0    1.651549   \n",
       "buy_interval                  0                1  52257.0    0.000000   \n",
       "sv_interval                   0             5112  52257.0    5.686388   \n",
       "expected_time_buy             0                1  52257.0    0.000000   \n",
       "expected_time_visit           0            13351  52257.0   -9.669298   \n",
       "last_buy                      0              189  52257.0   65.741317   \n",
       "last_visit                    0              189  52257.0   65.741317   \n",
       "multiple_buy                  0                1  52257.0    0.000000   \n",
       "multiple_visit                0                2  52257.0    0.255602   \n",
       "uniq_urls                     0              207  52257.0   86.656180   \n",
       "num_checkins                  0             4570  52257.0  721.848518   \n",
       "y_buy                         0                2  52257.0    0.003024   \n",
       "\n",
       "                             std       min    25%    50%         75%  \\\n",
       "isbuyer                 0.000000    0.0000    0.0    0.0    0.000000   \n",
       "buy_freq                     NaN       NaN    NaN    NaN         NaN   \n",
       "visit_freq              2.147955    1.0000    1.0    1.0    2.000000   \n",
       "buy_interval            0.000000    0.0000    0.0    0.0    0.000000   \n",
       "sv_interval            17.623555    0.0000    0.0    0.0    0.041667   \n",
       "expected_time_buy       0.000000    0.0000    0.0    0.0    0.000000   \n",
       "expected_time_visit    31.239030 -187.6156    0.0    0.0    0.000000   \n",
       "last_buy               53.484622    0.0000   19.0   52.0  106.000000   \n",
       "last_visit             53.484622    0.0000   19.0   52.0  106.000000   \n",
       "multiple_buy            0.000000    0.0000    0.0    0.0    0.000000   \n",
       "multiple_visit          0.436203    0.0000    0.0    0.0    1.000000   \n",
       "uniq_urls              61.996711   -1.0000   30.0   75.0  155.000000   \n",
       "num_checkins         1284.504018    1.0000  126.0  318.0  803.000000   \n",
       "y_buy                   0.054904    0.0000    0.0    0.0    0.000000   \n",
       "\n",
       "                             max  \n",
       "isbuyer                  0.00000  \n",
       "buy_freq                     NaN  \n",
       "visit_freq              84.00000  \n",
       "buy_interval             0.00000  \n",
       "sv_interval            184.91670  \n",
       "expected_time_buy        0.00000  \n",
       "expected_time_visit     91.40192  \n",
       "last_buy               188.00000  \n",
       "last_visit             188.00000  \n",
       "multiple_buy             0.00000  \n",
       "multiple_visit           1.00000  \n",
       "uniq_urls              206.00000  \n",
       "num_checkins         37091.00000  \n",
       "y_buy                    1.00000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "null_data= ads[ads.isnull().any(axis=1)] #create a data frame that has just the records with a missing value\n",
    "null_data.head(10) #see what it looks like\n",
    "getDfSummary(null_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Answer:The data is not missing at random. \n",
    "It correlates perfectly with \"isbuyer\", \"buy_interval\",\"expected_time_buy\" and \"multible_buy\" column. \n",
    "Apparently, if a person it not a buyer, there is no record for frequency of buying, interval of buying.\n",
    "Since there is no information about buying behavior if a person is not buyer, we cannot expect time of buying.\n",
    "Of course, the multiple_buy column is 0 is one is not a buyer at all.\n",
    "Thus, if \"isbuyer\" is 0, \"buy_freq\" will be a missing value and values for\"buy_interval\",\"expected_time_buy\" and \"multible_buy\" columns will all be 0. \n",
    "If we want to change the missing value to a number, it should be 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer:\n",
    "Based on getDfSummary(ads), we know \"isbuyer\", \"multiple_buy\",\"multiple_visit\" and \"y_buy\" has two distinct values. \n",
    "Thus, these four variables could be binary.\n",
    "To verify they are binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    52257\n",
       "1     2327\n",
       "Name: isbuyer, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads['isbuyer'].value_counts() #display distinct values and its frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    54237\n",
       "1      347\n",
       "Name: multiple_buy, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads['multiple_buy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39440\n",
       "1    15144\n",
       "Name: multiple_visit, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads['multiple_visit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    54331\n",
       "1      253\n",
       "Name: y_buy, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ads['y_buy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of them only take values 0 or 1.\n",
    "Thus, \"isbuyer\", \"multiple_buy\",\"multiple_visit\" and \"y_buy\" are indeed binary variables."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
